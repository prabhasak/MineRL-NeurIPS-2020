{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/p/prabhasa/.conda/envs/lensminerl/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/grads/p/prabhasa/.conda/envs/lensminerl/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Train or test algorithms on MineRLTreechopVectorObf-v0.\n",
    "\n",
    "- Author: Prabhasa Kalkur\n",
    "- Contact: prabhasa.94@gmail.com\n",
    "\n",
    "Config file for algo: --cfg-path\n",
    "Expert demo for fD algos: --demo-path (system-dependent)\n",
    "Env name: env_name\n",
    "WANDB logs: wandb.init (system-dependent)\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import minerl\n",
    "import os\n",
    "\n",
    "import gym\n",
    "import envs\n",
    "import numpy as np\n",
    "from envs.wrappers import MineRLObservationWrapper, MineRLActionWrapper, MineRLDiscreteActionWrapper, MineRLDeterministic\n",
    "from rl_algorithms import build_agent\n",
    "import rl_algorithms.common.env.utils as env_utils\n",
    "import rl_algorithms.common.helper_functions as common_utils\n",
    "from rl_algorithms.utils import Config\n",
    "\n",
    "from xvfbwrapper import Xvfb # only for ecelbw00202\n",
    "\n",
    "import wandb\n",
    "# wandb.config[\"more\"] = \"custom\"\n",
    "\n",
    "def parse_args() -> argparse.Namespace:\n",
    "    # configurations\n",
    "    parser = argparse.ArgumentParser(description=\"Pytorch RL algorithms\")\n",
    "    parser.add_argument(\n",
    "        \"--seed\", type=int, default=42, help=\"random seed for reproducibility\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cfg-path\",\n",
    "        type=str,\n",
    "        default=\"./configs/MineRLTreechopVectorObf_v0/dqn.py\", # PARAM 1: ALGORITHM\n",
    "        help=\"config path\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test\", dest=\"test\", action=\"store_true\", help=\"test mode (no training)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--load-from\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"load the saved model and optimizer at the beginning\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--off-render\", dest=\"render\", action=\"store_false\", help=\"turn off rendering\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--render-after\",\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"start rendering after the input number of episode\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--log\", dest=\"log\", action=\"store_false\", help=\"turn on logging\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save-period\", type=int, default=3, help=\"save model period\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--episode-num\", type=int, default=30, help=\"total episode num\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max-episode-steps\", type=int, default=0, help=\"max episode step\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--interim-test-num\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"number of test during training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--demo-path\",\n",
    "        type=str,\n",
    "        # PARAM 2: FOR FD ALGOS\n",
    "        default = \"/home/grads/p/prabhasa/MineRL2020/data/MineRLTreechopVectorObf-v0\",  # ecelbw00202\n",
    "        # default=\"data/MineRLTreechopVectorObf-v0\",  # PK laptop\n",
    "        help=\"demonstration path for learning from demo\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--integration-test\",\n",
    "        dest=\"integration_test\",\n",
    "        action=\"store_true\",\n",
    "        help=\"indicate integration test\",\n",
    "    )\n",
    "\n",
    "#     return parser.parse_args()\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main.\"\"\"\n",
    "    args, unknown = parse_args()\n",
    "\n",
    "    # PARAM 3: INITILAIZE WANDB\n",
    "    wandb.init(name='dqn_mtc_obf_1', project=\"lensminerl_treechop_obf\", dir='/home/grads/p/prabhasa/MineRL2020/medipixel', group='dry_run', reinit=True, sync_tensorboard=True) # ecelbw00202\n",
    "    # wandb.init(name='dqn_mtc_obf_1', project=\"wandb_on_minerl\", dir='C:/GitHub/MineRL-NeurIPS-2020', group='dry_run', reinit=True, sync_tensorboard=True) # PK laptop: locally cloned repo\n",
    "    # wandb.init(name='dqn_mtc_obf_1', project=\"wandb_on_minerl\", dir='C:/MineRL/medipixel', group='dry_run', reinit=True, sync_tensorboard=True) # PK laptop: locally run code\n",
    "    # wandb.tensorboard.patch(tensorboardX=True, pytorch=True)\n",
    "\n",
    "    # PARAM 3: env initialization and wrappers\n",
    "    env_name = \"MineRLTreechopVectorObf-v0\"\n",
    "    # env_name = \"MineRLObtainDiamondVectorObf-v0\"\n",
    "    env = gym.make(env_name)\n",
    "    env = MineRLObservationWrapper(env)\n",
    "    env = MineRLActionWrapper(env)\n",
    "    env = MineRLDiscreteActionWrapper(env)  # PARAM 4.1: FOR DISCRETE ACTION SPACES (K-MEANS)\n",
    "    env = MineRLDeterministic(env, args.seed)\n",
    "    env = env_utils.set_env(env, args)\n",
    "\n",
    "    # set a random seed\n",
    "    common_utils.set_random_seed(args.seed, env)\n",
    "\n",
    "    # run\n",
    "    NOWTIMES = datetime.datetime.now()\n",
    "    curr_time = NOWTIMES.strftime(\"%y%m%d_%H%M%S\")\n",
    "\n",
    "    cfg = Config.fromfile(args.cfg_path)\n",
    "\n",
    "    # If running integration test, simplify experiment\n",
    "    if args.integration_test:\n",
    "        cfg = common_utils.set_cfg_for_intergration_test(cfg)\n",
    "\n",
    "    # PK: Added np.array to obs_space and changed is_discrete\n",
    "    cfg.agent.env_info = dict(\n",
    "        name=env_name,\n",
    "        observation_space=np.array(env.observation_space),\n",
    "        action_space=env.action_space,\n",
    "        is_discrete=True,  # PARAM 4.2: FOR DISCRETE ACTION SPACES\n",
    "    )\n",
    "    cfg.agent.log_cfg = dict(agent=cfg.agent.type, curr_time=curr_time)\n",
    "    build_args = dict(args=args, env=env)\n",
    "    agent = build_agent(cfg.agent, build_args)\n",
    "\n",
    "    if not args.test:\n",
    "        agent.train()\n",
    "    else:\n",
    "        agent.test()\n",
    "\n",
    "    wandb.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/prabhasak/lensminerl_treechop_obf\" target=\"_blank\">https://app.wandb.ai/prabhasak/lensminerl_treechop_obf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/prabhasak/lensminerl_treechop_obf/runs/23djoj0q\" target=\"_blank\">https://app.wandb.ai/prabhasak/lensminerl_treechop_obf/runs/23djoj0q</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] episode 2, episode step: 8000, total step: 16000, total score: 0.000000\n",
      "epsilon: 0.940610, loss: 3.284729, avg q-value: 0.028332 (spent 0.358096 sec/step)\n",
      "\n",
      "[INFO] episode 3, episode step: 8000, total step: 24000, total score: 0.000000\n",
      "epsilon: 0.861410, loss: 3.897083, avg q-value: 0.011291 (spent 0.460615 sec/step)\n",
      "\n",
      "[INFO] episode 4, episode step: 7082, total step: 31082, total score: 0.000000\n",
      "epsilon: 0.791298, loss: 3.359669, avg q-value: 0.004145 (spent 0.459518 sec/step)\n",
      "\n",
      "[INFO] episode 5, episode step: 8000, total step: 39082, total score: 0.000000\n",
      "epsilon: 0.712098, loss: 2.875367, avg q-value: 0.034729 (spent 0.459015 sec/step)\n",
      "\n",
      "[INFO] episode 6, episode step: 8000, total step: 47082, total score: 0.000000\n",
      "epsilon: 0.632898, loss: 2.603057, avg q-value: 0.024256 (spent 0.466887 sec/step)\n",
      "\n",
      "[INFO] episode 7, episode step: 8000, total step: 55082, total score: 0.000000\n",
      "epsilon: 0.553698, loss: 2.287432, avg q-value: 0.018249 (spent 0.476490 sec/step)\n",
      "\n",
      "[INFO] episode 8, episode step: 8000, total step: 63082, total score: 0.000000\n",
      "epsilon: 0.474498, loss: 2.007169, avg q-value: 0.023192 (spent 0.485866 sec/step)\n",
      "\n",
      "[INFO] episode 9, episode step: 8000, total step: 71082, total score: 0.000000\n",
      "epsilon: 0.395298, loss: 1.419695, avg q-value: 0.023835 (spent 0.506142 sec/step)\n",
      "\n",
      "[INFO] episode 10, episode step: 8000, total step: 79082, total score: 0.000000\n",
      "epsilon: 0.316098, loss: 0.816847, avg q-value: 0.019846 (spent 0.559468 sec/step)\n",
      "\n",
      "[INFO] episode 11, episode step: 8000, total step: 87082, total score: 1.000000\n",
      "epsilon: 0.236898, loss: 0.535940, avg q-value: 0.018244 (spent 0.600643 sec/step)\n",
      "\n",
      "[INFO] episode 12, episode step: 4056, total step: 91138, total score: 1.000000\n",
      "epsilon: 0.196744, loss: 0.502157, avg q-value: 0.020120 (spent 0.611004 sec/step)\n",
      "\n",
      "[INFO] episode 13, episode step: 8000, total step: 99138, total score: 2.000000\n",
      "epsilon: 0.117544, loss: 0.426951, avg q-value: 0.021451 (spent 0.618229 sec/step)\n",
      "\n",
      "[INFO] episode 14, episode step: 8000, total step: 107138, total score: 3.000000\n",
      "epsilon: 0.038344, loss: 0.420066, avg q-value: 0.025294 (spent 0.621946 sec/step)\n",
      "\n",
      "[INFO] episode 15, episode step: 8000, total step: 115138, total score: 5.000000\n",
      "epsilon: 0.010000, loss: 0.450418, avg q-value: 0.040913 (spent 0.632024 sec/step)\n",
      "\n",
      "[INFO] episode 16, episode step: 8000, total step: 123138, total score: 0.000000\n",
      "epsilon: 0.010000, loss: 0.466337, avg q-value: 0.069969 (spent 0.632694 sec/step)\n",
      "\n",
      "[INFO] episode 17, episode step: 8000, total step: 131138, total score: 3.000000\n",
      "epsilon: 0.010000, loss: 0.506026, avg q-value: 0.194944 (spent 0.644851 sec/step)\n",
      "\n",
      "[INFO] episode 18, episode step: 8000, total step: 139138, total score: 1.000000\n",
      "epsilon: 0.010000, loss: 1.919633, avg q-value: 0.228927 (spent 0.641782 sec/step)\n",
      "\n",
      "[INFO] episode 19, episode step: 8000, total step: 147138, total score: 0.000000\n",
      "epsilon: 0.010000, loss: 2.061740, avg q-value: 0.284719 (spent 0.650355 sec/step)\n",
      "\n",
      "[INFO] episode 20, episode step: 8000, total step: 155138, total score: 4.000000\n",
      "epsilon: 0.010000, loss: 2.148810, avg q-value: 0.324182 (spent 0.646137 sec/step)\n",
      "\n",
      "[INFO] episode 21, episode step: 8000, total step: 163138, total score: 0.000000\n",
      "epsilon: 0.010000, loss: 2.072020, avg q-value: 0.345836 (spent 0.646160 sec/step)\n",
      "\n",
      "[INFO] episode 22, episode step: 8000, total step: 171138, total score: 3.000000\n",
      "epsilon: 0.010000, loss: 1.746502, avg q-value: 0.369556 (spent 0.649640 sec/step)\n",
      "\n",
      "[INFO] episode 23, episode step: 8000, total step: 179138, total score: 2.000000\n",
      "epsilon: 0.010000, loss: 1.351613, avg q-value: 0.381456 (spent 0.647807 sec/step)\n",
      "\n",
      "[INFO] episode 24, episode step: 8000, total step: 187138, total score: 4.000000\n",
      "epsilon: 0.010000, loss: 1.257123, avg q-value: 0.424498 (spent 0.650464 sec/step)\n",
      "\n",
      "[INFO] episode 25, episode step: 8000, total step: 195138, total score: 5.000000\n",
      "epsilon: 0.010000, loss: 1.202586, avg q-value: 0.441170 (spent 0.644792 sec/step)\n",
      "\n",
      "[INFO] episode 26, episode step: 8000, total step: 203138, total score: 0.000000\n",
      "epsilon: 0.010000, loss: 1.329966, avg q-value: 0.541274 (spent 0.654874 sec/step)\n",
      "\n",
      "[INFO] episode 27, episode step: 8000, total step: 211138, total score: 1.000000\n",
      "epsilon: 0.010000, loss: 2.562889, avg q-value: 0.568924 (spent 0.653747 sec/step)\n",
      "\n",
      "[INFO] episode 28, episode step: 8000, total step: 219138, total score: 5.000000\n",
      "epsilon: 0.010000, loss: 2.508411, avg q-value: 0.616046 (spent 0.648720 sec/step)\n",
      "\n",
      "[INFO] episode 29, episode step: 8000, total step: 227138, total score: 0.000000\n",
      "epsilon: 0.010000, loss: 2.476420, avg q-value: 0.650133 (spent 0.649088 sec/step)\n",
      "\n",
      "[INFO] episode 30, episode step: 8000, total step: 235138, total score: 0.000000\n",
      "epsilon: 0.010000, loss: 2.399502, avg q-value: 0.619399 (spent 0.647625 sec/step)\n",
      "\n",
      "[INFO] episode 31, episode step: 8000, total step: 243138, total score: 0.000000\n",
      "epsilon: 0.010000, loss: 2.308845, avg q-value: 0.584725 (spent 0.653185 sec/step)\n",
      "\n",
      "[INFO] episode 32, episode step: 8000, total step: 251138, total score: 0.000000\n",
      "epsilon: 0.010000, loss: 2.249503, avg q-value: 0.573416 (spent 0.649538 sec/step)\n",
      "\n",
      "[INFO] episode 33, episode step: 8000, total step: 259138, total score: 0.000000\n",
      "epsilon: 0.010000, loss: 2.165364, avg q-value: 0.479565 (spent 0.653741 sec/step)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0b286b9802d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXvfb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m740\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolordepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mvdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8f8c97cb10a7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MineRL2020/medipixel/MineRL-NeurIPS-2020/rl_algorithms/dqn/agent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                             \u001b[0mexperience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m                             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_priorities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MineRL2020/medipixel/MineRL-NeurIPS-2020/rl_algorithms/dqn/learner.py\u001b[0m in \u001b[0;36mupdate_model\u001b[0;34m(self, experience)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             dq_loss_n_element_wise, q_values_n = self.loss_fn(\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperience_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_cfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             )\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MineRL2020/medipixel/MineRL-NeurIPS-2020/rl_algorithms/dqn/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model, target_model, experiences, gamma, head_cfg)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mnext_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mnext_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mnext_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MineRL2020/medipixel/MineRL-NeurIPS-2020/rl_algorithms/common/networks/brain.py\u001b[0m in \u001b[0;36mforward_\u001b[0;34m(self, x, n_tau_samples)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tau_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MineRL2020/medipixel/MineRL-NeurIPS-2020/rl_algorithms/dqn/networks.py\u001b[0m in \u001b[0;36mforward_\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mval_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_hidden_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0madvantage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvantage_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0madvantage_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madvantage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lensminerl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lensminerl/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lensminerl/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    vdisplay = Xvfb(width=1280, height=740, colordepth=16)\n",
    "    vdisplay.start()\n",
    "    main()\n",
    "    vdisplay.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
